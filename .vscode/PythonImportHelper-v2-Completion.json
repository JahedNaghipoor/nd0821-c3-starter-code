[
    {
        "label": "numpy",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "numpy",
        "description": "numpy",
        "detail": "numpy",
        "documentation": {}
    },
    {
        "label": "LabelBinarizer",
        "importPath": "sklearn.preprocessing",
        "description": "sklearn.preprocessing",
        "isExtraImport": true,
        "detail": "sklearn.preprocessing",
        "documentation": {}
    },
    {
        "label": "OneHotEncoder",
        "importPath": "sklearn.preprocessing",
        "description": "sklearn.preprocessing",
        "isExtraImport": true,
        "detail": "sklearn.preprocessing",
        "documentation": {}
    },
    {
        "label": "fbeta_score",
        "importPath": "sklearn.metrics",
        "description": "sklearn.metrics",
        "isExtraImport": true,
        "detail": "sklearn.metrics",
        "documentation": {}
    },
    {
        "label": "precision_score",
        "importPath": "sklearn.metrics",
        "description": "sklearn.metrics",
        "isExtraImport": true,
        "detail": "sklearn.metrics",
        "documentation": {}
    },
    {
        "label": "recall_score",
        "importPath": "sklearn.metrics",
        "description": "sklearn.metrics",
        "isExtraImport": true,
        "detail": "sklearn.metrics",
        "documentation": {}
    },
    {
        "label": "GradientBoostingClassifier",
        "importPath": "sklearn.ensemble",
        "description": "sklearn.ensemble",
        "isExtraImport": true,
        "detail": "sklearn.ensemble",
        "documentation": {}
    },
    {
        "label": "GridSearchCV",
        "importPath": "sklearn.model_selection",
        "description": "sklearn.model_selection",
        "isExtraImport": true,
        "detail": "sklearn.model_selection",
        "documentation": {}
    },
    {
        "label": "train_test_split",
        "importPath": "sklearn.model_selection",
        "description": "sklearn.model_selection",
        "isExtraImport": true,
        "detail": "sklearn.model_selection",
        "documentation": {}
    },
    {
        "label": "train_test_split",
        "importPath": "sklearn.model_selection",
        "description": "sklearn.model_selection",
        "isExtraImport": true,
        "detail": "sklearn.model_selection",
        "documentation": {}
    },
    {
        "label": "pickle",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "pickle",
        "description": "pickle",
        "detail": "pickle",
        "documentation": {}
    },
    {
        "label": "os",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "os",
        "description": "os",
        "detail": "os",
        "documentation": {}
    },
    {
        "label": "path",
        "importPath": "os",
        "description": "os",
        "isExtraImport": true,
        "detail": "os",
        "documentation": {}
    },
    {
        "label": "pandas",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "pandas",
        "description": "pandas",
        "detail": "pandas",
        "documentation": {}
    },
    {
        "label": "pytest",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "pytest",
        "description": "pytest",
        "detail": "pytest",
        "documentation": {}
    },
    {
        "label": "*",
        "importPath": "data",
        "description": "data",
        "isExtraImport": true,
        "detail": "data",
        "documentation": {}
    },
    {
        "label": "load_data",
        "importPath": "data",
        "description": "data",
        "isExtraImport": true,
        "detail": "data",
        "documentation": {}
    },
    {
        "label": "process_data",
        "importPath": "ml.data",
        "description": "ml.data",
        "isExtraImport": true,
        "detail": "ml.data",
        "documentation": {}
    },
    {
        "label": "process_data",
        "importPath": "ml.data",
        "description": "ml.data",
        "isExtraImport": true,
        "detail": "ml.data",
        "documentation": {}
    },
    {
        "label": "compute_model_metrics",
        "importPath": "ml.model",
        "description": "ml.model",
        "isExtraImport": true,
        "detail": "ml.model",
        "documentation": {}
    },
    {
        "label": "inference",
        "importPath": "ml.model",
        "description": "ml.model",
        "isExtraImport": true,
        "detail": "ml.model",
        "documentation": {}
    },
    {
        "label": "train_model",
        "importPath": "ml.model",
        "description": "ml.model",
        "isExtraImport": true,
        "detail": "ml.model",
        "documentation": {}
    },
    {
        "label": "train_model",
        "importPath": "ml.model",
        "description": "ml.model",
        "isExtraImport": true,
        "detail": "ml.model",
        "documentation": {}
    },
    {
        "label": "compute_model_metrics",
        "importPath": "ml.model",
        "description": "ml.model",
        "isExtraImport": true,
        "detail": "ml.model",
        "documentation": {}
    },
    {
        "label": "inference",
        "importPath": "ml.model",
        "description": "ml.model",
        "isExtraImport": true,
        "detail": "ml.model",
        "documentation": {}
    },
    {
        "label": "argparse",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "argparse",
        "description": "argparse",
        "detail": "argparse",
        "documentation": {}
    },
    {
        "label": "importlib",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "importlib",
        "description": "importlib",
        "detail": "importlib",
        "documentation": {}
    },
    {
        "label": "inspect",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "inspect",
        "description": "inspect",
        "detail": "inspect",
        "documentation": {}
    },
    {
        "label": "sys",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "sys",
        "description": "sys",
        "detail": "sys",
        "documentation": {}
    },
    {
        "label": "setuptools",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "setuptools",
        "description": "setuptools",
        "detail": "setuptools",
        "documentation": {}
    },
    {
        "label": "process_data",
        "kind": 2,
        "importPath": "starter.starter.ml.data",
        "description": "starter.starter.ml.data",
        "peekOfCode": "def process_data(X, categorical_features=[], label=None, training=True, encoder=None, lb=None):\n    if label is not None:\n        y = X[label]\n        X = X.drop([label], axis=1)\n    else:\n        y = np.array([])\n    X_categorical = X[categorical_features].values\n    X_continuous = X.drop(*[categorical_features], axis=1)\n    if training is True:\n        encoder = OneHotEncoder(sparse=False, handle_unknown=\"ignore\")",
        "detail": "starter.starter.ml.data",
        "documentation": {}
    },
    {
        "label": "train_model",
        "kind": 2,
        "importPath": "starter.starter.ml.model",
        "description": "starter.starter.ml.model",
        "peekOfCode": "def train_model(X_train, y_train, path):\n    \"\"\"\n    Trains a machine learning model and returns it.\n    Inputs\n    ------\n    X_train : np.array\n        Training data.\n    y_train : np.array\n        Labels.\n    Returns",
        "detail": "starter.starter.ml.model",
        "documentation": {}
    },
    {
        "label": "compute_model_metrics",
        "kind": 2,
        "importPath": "starter.starter.ml.model",
        "description": "starter.starter.ml.model",
        "peekOfCode": "def compute_model_metrics(y, preds):\n    \"\"\"\n    Validates the trained machine learning model using precision, recall, and F1.\n    Inputs\n    ------\n    y : np.array\n        Known labels, binarized.\n    preds : np.array\n        Predicted labels, binarized.\n    Returns",
        "detail": "starter.starter.ml.model",
        "documentation": {}
    },
    {
        "label": "inference",
        "kind": 2,
        "importPath": "starter.starter.ml.model",
        "description": "starter.starter.ml.model",
        "peekOfCode": "def inference(model, X):\n    \"\"\" Run model inferences and return the predictions.\n    Inputs\n    ------\n    model : sklearn model\n        Trained machine learning model.\n    X : np.array\n        Data used for prediction.\n    Returns\n    -------",
        "detail": "starter.starter.ml.model",
        "documentation": {}
    },
    {
        "label": "RANDOM_STATE",
        "kind": 5,
        "importPath": "starter.starter.ml.model",
        "description": "starter.starter.ml.model",
        "peekOfCode": "RANDOM_STATE = 42\n# Optional: implement hyperparameter tuning.\ndef train_model(X_train, y_train, path):\n    \"\"\"\n    Trains a machine learning model and returns it.\n    Inputs\n    ------\n    X_train : np.array\n        Training data.\n    y_train : np.array",
        "detail": "starter.starter.ml.model",
        "documentation": {}
    },
    {
        "label": "root",
        "kind": 2,
        "importPath": "starter.starter.tests.test_model",
        "description": "starter.starter.tests.test_model",
        "peekOfCode": "def root(): # root directory\n    return os.getcwd()\n@pytest.fixture\ndef files(root):\n    load_path = os.path.join(root, data_dir, \"census.csv\")\n    data = load_data(load_path)\n    model = os.path.join(root, model_dir, \"gbclassifier.pkl\")\n    with open(model, \"rb\") as f:\n        model = pickle.load(f)\n    encoder = os.path.join(root,model_dir, \"encoder.pkl\")",
        "detail": "starter.starter.tests.test_model",
        "documentation": {}
    },
    {
        "label": "files",
        "kind": 2,
        "importPath": "starter.starter.tests.test_model",
        "description": "starter.starter.tests.test_model",
        "peekOfCode": "def files(root):\n    load_path = os.path.join(root, data_dir, \"census.csv\")\n    data = load_data(load_path)\n    model = os.path.join(root, model_dir, \"gbclassifier.pkl\")\n    with open(model, \"rb\") as f:\n        model = pickle.load(f)\n    encoder = os.path.join(root,model_dir, \"encoder.pkl\")\n    with open(encoder, \"rb\") as f:\n        encoder = pickle.load(f)\n    lb = os.path.join(root, model_dir, \"lb.pkl\")",
        "detail": "starter.starter.tests.test_model",
        "documentation": {}
    },
    {
        "label": "train_test_data",
        "kind": 2,
        "importPath": "starter.starter.tests.test_model",
        "description": "starter.starter.tests.test_model",
        "peekOfCode": "def train_test_data(files):\n    data, _, _, _ = files\n    train, test = train_test_split(data, test_size=0.20, random_state=42)\n    return train, test\ndef test_train_model(files, root):\n    data, model, encoder, lb = files\n    train, test = train_test_split(data, test_size=0.20, random_state=42)\n    cat_features = [\n        \"workclass\",\n        \"education\",",
        "detail": "starter.starter.tests.test_model",
        "documentation": {}
    },
    {
        "label": "test_train_model",
        "kind": 2,
        "importPath": "starter.starter.tests.test_model",
        "description": "starter.starter.tests.test_model",
        "peekOfCode": "def test_train_model(files, root):\n    data, model, encoder, lb = files\n    train, test = train_test_split(data, test_size=0.20, random_state=42)\n    cat_features = [\n        \"workclass\",\n        \"education\",\n        \"marital-status\",\n        \"occupation\",\n        \"relationship\",\n        \"race\",",
        "detail": "starter.starter.tests.test_model",
        "documentation": {}
    },
    {
        "label": "data_dir",
        "kind": 5,
        "importPath": "starter.starter.tests.test_model",
        "description": "starter.starter.tests.test_model",
        "peekOfCode": "data_dir = \"../data/\"\nmodel_dir = \"../model/\"\n@pytest.fixture \ndef root(): # root directory\n    return os.getcwd()\n@pytest.fixture\ndef files(root):\n    load_path = os.path.join(root, data_dir, \"census.csv\")\n    data = load_data(load_path)\n    model = os.path.join(root, model_dir, \"gbclassifier.pkl\")",
        "detail": "starter.starter.tests.test_model",
        "documentation": {}
    },
    {
        "label": "model_dir",
        "kind": 5,
        "importPath": "starter.starter.tests.test_model",
        "description": "starter.starter.tests.test_model",
        "peekOfCode": "model_dir = \"../model/\"\n@pytest.fixture \ndef root(): # root directory\n    return os.getcwd()\n@pytest.fixture\ndef files(root):\n    load_path = os.path.join(root, data_dir, \"census.csv\")\n    data = load_data(load_path)\n    model = os.path.join(root, model_dir, \"gbclassifier.pkl\")\n    with open(model, \"rb\") as f:",
        "detail": "starter.starter.tests.test_model",
        "documentation": {}
    },
    {
        "label": "clean_data",
        "kind": 2,
        "importPath": "starter.starter.data",
        "description": "starter.starter.data",
        "peekOfCode": "def clean_data(df):\n    df.replace({'?': None}, inplace=True)\n    df.dropna(inplace=True)\n    df.drop([\"capital-gain\", \"capital-loss\", \"education-num\", \"fnlgt\"], axis=\"columns\", inplace=True)\n    return df\ndef load_data(path):\n    return pd.read_csv(path, skipinitialspace=True)\ndef save_data(df, path):\n    return df.to_csv(path, index=False)\nif __name__ == \"__main__\":",
        "detail": "starter.starter.data",
        "documentation": {}
    },
    {
        "label": "load_data",
        "kind": 2,
        "importPath": "starter.starter.data",
        "description": "starter.starter.data",
        "peekOfCode": "def load_data(path):\n    return pd.read_csv(path, skipinitialspace=True)\ndef save_data(df, path):\n    return df.to_csv(path, index=False)\nif __name__ == \"__main__\":\n    dir = \"../data/\"\n    load_path = os.path.join(dir, \"census.csv\")\n    df = load_data(load_path)\n    clean_df = clean_data(df)\n    save_path = os.path.join(dir, \"census_clean.csv\")",
        "detail": "starter.starter.data",
        "documentation": {}
    },
    {
        "label": "save_data",
        "kind": 2,
        "importPath": "starter.starter.data",
        "description": "starter.starter.data",
        "peekOfCode": "def save_data(df, path):\n    return df.to_csv(path, index=False)\nif __name__ == \"__main__\":\n    dir = \"../data/\"\n    load_path = os.path.join(dir, \"census.csv\")\n    df = load_data(load_path)\n    clean_df = clean_data(df)\n    save_path = os.path.join(dir, \"census_clean.csv\")\n    save_data(clean_df, save_path)\n    print(\"Done\")",
        "detail": "starter.starter.data",
        "documentation": {}
    },
    {
        "label": "data_dir",
        "kind": 5,
        "importPath": "starter.starter.train_model",
        "description": "starter.starter.train_model",
        "peekOfCode": "data_dir = \"../data/\"   # the directory where the data is stored.\ndata_path = os.path.join(data_dir + \"census_clean.csv\") # path to the clean data\ndata = load_data(data_path)\n# Optional enhancement, use K-fold cross validation instead of a train-test split.\ntrain, test = train_test_split(data, test_size=0.20)    # 20% of the data will be used for testing\ncat_features = [\n    \"workclass\",\n    \"education\",\n    \"marital-status\",\n    \"occupation\",",
        "detail": "starter.starter.train_model",
        "documentation": {}
    },
    {
        "label": "data_path",
        "kind": 5,
        "importPath": "starter.starter.train_model",
        "description": "starter.starter.train_model",
        "peekOfCode": "data_path = os.path.join(data_dir + \"census_clean.csv\") # path to the clean data\ndata = load_data(data_path)\n# Optional enhancement, use K-fold cross validation instead of a train-test split.\ntrain, test = train_test_split(data, test_size=0.20)    # 20% of the data will be used for testing\ncat_features = [\n    \"workclass\",\n    \"education\",\n    \"marital-status\",\n    \"occupation\",\n    \"relationship\",",
        "detail": "starter.starter.train_model",
        "documentation": {}
    },
    {
        "label": "data",
        "kind": 5,
        "importPath": "starter.starter.train_model",
        "description": "starter.starter.train_model",
        "peekOfCode": "data = load_data(data_path)\n# Optional enhancement, use K-fold cross validation instead of a train-test split.\ntrain, test = train_test_split(data, test_size=0.20)    # 20% of the data will be used for testing\ncat_features = [\n    \"workclass\",\n    \"education\",\n    \"marital-status\",\n    \"occupation\",\n    \"relationship\",\n    \"race\",",
        "detail": "starter.starter.train_model",
        "documentation": {}
    },
    {
        "label": "cat_features",
        "kind": 5,
        "importPath": "starter.starter.train_model",
        "description": "starter.starter.train_model",
        "peekOfCode": "cat_features = [\n    \"workclass\",\n    \"education\",\n    \"marital-status\",\n    \"occupation\",\n    \"relationship\",\n    \"race\",\n    \"sex\",\n    \"native-country\",\n]   ",
        "detail": "starter.starter.train_model",
        "documentation": {}
    },
    {
        "label": "model_dir",
        "kind": 5,
        "importPath": "starter.starter.train_model",
        "description": "starter.starter.train_model",
        "peekOfCode": "model_dir = \"../model\"  # the directory where the model will be stored.\nmodel_path = os.path.join(model_dir + \"/gbc_model.pkl\") # path to the model\nclassifier = train_model(X_train, y_train, model_path)  # train the model\ny_train_predict = inference(classifier, X_train)    # make predictions on the training data\ntrain_precision, train_recall, train_fbeta = compute_model_metrics(y_train, y_train_predict)    # compute the metrics\nprint(f\"train_precision: {train_precision}, train_recall: {train_recall}, train_fbeta: {train_fbeta}\")  # print the metrics\ny_test_predict = inference(classifier, X_test)  # make predictions on the test data\ntest_precision, test_recall, test_fbeta = compute_model_metrics(y_test, y_test_predict) # compute the metrics\nprint(f\"test_precision: {test_precision}, test_recall: {test_recall}, test_fbeta: {test_fbeta}\")    # print the metrics",
        "detail": "starter.starter.train_model",
        "documentation": {}
    },
    {
        "label": "model_path",
        "kind": 5,
        "importPath": "starter.starter.train_model",
        "description": "starter.starter.train_model",
        "peekOfCode": "model_path = os.path.join(model_dir + \"/gbc_model.pkl\") # path to the model\nclassifier = train_model(X_train, y_train, model_path)  # train the model\ny_train_predict = inference(classifier, X_train)    # make predictions on the training data\ntrain_precision, train_recall, train_fbeta = compute_model_metrics(y_train, y_train_predict)    # compute the metrics\nprint(f\"train_precision: {train_precision}, train_recall: {train_recall}, train_fbeta: {train_fbeta}\")  # print the metrics\ny_test_predict = inference(classifier, X_test)  # make predictions on the test data\ntest_precision, test_recall, test_fbeta = compute_model_metrics(y_test, y_test_predict) # compute the metrics\nprint(f\"test_precision: {test_precision}, test_recall: {test_recall}, test_fbeta: {test_fbeta}\")    # print the metrics",
        "detail": "starter.starter.train_model",
        "documentation": {}
    },
    {
        "label": "classifier",
        "kind": 5,
        "importPath": "starter.starter.train_model",
        "description": "starter.starter.train_model",
        "peekOfCode": "classifier = train_model(X_train, y_train, model_path)  # train the model\ny_train_predict = inference(classifier, X_train)    # make predictions on the training data\ntrain_precision, train_recall, train_fbeta = compute_model_metrics(y_train, y_train_predict)    # compute the metrics\nprint(f\"train_precision: {train_precision}, train_recall: {train_recall}, train_fbeta: {train_fbeta}\")  # print the metrics\ny_test_predict = inference(classifier, X_test)  # make predictions on the test data\ntest_precision, test_recall, test_fbeta = compute_model_metrics(y_test, y_test_predict) # compute the metrics\nprint(f\"test_precision: {test_precision}, test_recall: {test_recall}, test_fbeta: {test_fbeta}\")    # print the metrics",
        "detail": "starter.starter.train_model",
        "documentation": {}
    },
    {
        "label": "y_train_predict",
        "kind": 5,
        "importPath": "starter.starter.train_model",
        "description": "starter.starter.train_model",
        "peekOfCode": "y_train_predict = inference(classifier, X_train)    # make predictions on the training data\ntrain_precision, train_recall, train_fbeta = compute_model_metrics(y_train, y_train_predict)    # compute the metrics\nprint(f\"train_precision: {train_precision}, train_recall: {train_recall}, train_fbeta: {train_fbeta}\")  # print the metrics\ny_test_predict = inference(classifier, X_test)  # make predictions on the test data\ntest_precision, test_recall, test_fbeta = compute_model_metrics(y_test, y_test_predict) # compute the metrics\nprint(f\"test_precision: {test_precision}, test_recall: {test_recall}, test_fbeta: {test_fbeta}\")    # print the metrics",
        "detail": "starter.starter.train_model",
        "documentation": {}
    },
    {
        "label": "y_test_predict",
        "kind": 5,
        "importPath": "starter.starter.train_model",
        "description": "starter.starter.train_model",
        "peekOfCode": "y_test_predict = inference(classifier, X_test)  # make predictions on the test data\ntest_precision, test_recall, test_fbeta = compute_model_metrics(y_test, y_test_predict) # compute the metrics\nprint(f\"test_precision: {test_precision}, test_recall: {test_recall}, test_fbeta: {test_fbeta}\")    # print the metrics",
        "detail": "starter.starter.train_model",
        "documentation": {}
    },
    {
        "label": "run_sanity_check",
        "kind": 2,
        "importPath": "starter.sanitycheck",
        "description": "starter.sanitycheck",
        "peekOfCode": "def run_sanity_check(test_dir):\n    #assert path.isdir(test_dir), FAIL_COLOR+f\"No direcotry named {test_dir} found in {os.getcwd()}\"\n    print('This script will perform a sanity test to ensure your code meets the criteria in the rubric.\\n')\n    print('Please enter the path to the file that contains your test cases for the GET() and POST() methods')\n    print('The path should be something like abc/def/test_xyz.py')\n    filepath = input('> ')\n    assert path.exists(filepath), f\"File {filepath} does not exist.\"\n    sys.path.append(path.dirname(filepath))\n    module_name = path.splitext(path.basename(filepath))[0]\n    module = importlib.import_module(module_name)",
        "detail": "starter.sanitycheck",
        "documentation": {}
    },
    {
        "label": "FAIL_COLOR",
        "kind": 5,
        "importPath": "starter.sanitycheck",
        "description": "starter.sanitycheck",
        "peekOfCode": "FAIL_COLOR = '\\033[91m'\nOK_COLOR = '\\033[92m'\nWARN_COLOR = '\\033[93m'\ndef run_sanity_check(test_dir):\n    #assert path.isdir(test_dir), FAIL_COLOR+f\"No direcotry named {test_dir} found in {os.getcwd()}\"\n    print('This script will perform a sanity test to ensure your code meets the criteria in the rubric.\\n')\n    print('Please enter the path to the file that contains your test cases for the GET() and POST() methods')\n    print('The path should be something like abc/def/test_xyz.py')\n    filepath = input('> ')\n    assert path.exists(filepath), f\"File {filepath} does not exist.\"",
        "detail": "starter.sanitycheck",
        "documentation": {}
    },
    {
        "label": "OK_COLOR",
        "kind": 5,
        "importPath": "starter.sanitycheck",
        "description": "starter.sanitycheck",
        "peekOfCode": "OK_COLOR = '\\033[92m'\nWARN_COLOR = '\\033[93m'\ndef run_sanity_check(test_dir):\n    #assert path.isdir(test_dir), FAIL_COLOR+f\"No direcotry named {test_dir} found in {os.getcwd()}\"\n    print('This script will perform a sanity test to ensure your code meets the criteria in the rubric.\\n')\n    print('Please enter the path to the file that contains your test cases for the GET() and POST() methods')\n    print('The path should be something like abc/def/test_xyz.py')\n    filepath = input('> ')\n    assert path.exists(filepath), f\"File {filepath} does not exist.\"\n    sys.path.append(path.dirname(filepath))",
        "detail": "starter.sanitycheck",
        "documentation": {}
    },
    {
        "label": "WARN_COLOR",
        "kind": 5,
        "importPath": "starter.sanitycheck",
        "description": "starter.sanitycheck",
        "peekOfCode": "WARN_COLOR = '\\033[93m'\ndef run_sanity_check(test_dir):\n    #assert path.isdir(test_dir), FAIL_COLOR+f\"No direcotry named {test_dir} found in {os.getcwd()}\"\n    print('This script will perform a sanity test to ensure your code meets the criteria in the rubric.\\n')\n    print('Please enter the path to the file that contains your test cases for the GET() and POST() methods')\n    print('The path should be something like abc/def/test_xyz.py')\n    filepath = input('> ')\n    assert path.exists(filepath), f\"File {filepath} does not exist.\"\n    sys.path.append(path.dirname(filepath))\n    module_name = path.splitext(path.basename(filepath))[0]",
        "detail": "starter.sanitycheck",
        "documentation": {}
    }
]