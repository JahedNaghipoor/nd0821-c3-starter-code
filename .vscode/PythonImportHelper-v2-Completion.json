[
    {
        "label": "numpy",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "numpy",
        "description": "numpy",
        "detail": "numpy",
        "documentation": {}
    },
    {
        "label": "LabelBinarizer",
        "importPath": "sklearn.preprocessing",
        "description": "sklearn.preprocessing",
        "isExtraImport": true,
        "detail": "sklearn.preprocessing",
        "documentation": {}
    },
    {
        "label": "OneHotEncoder",
        "importPath": "sklearn.preprocessing",
        "description": "sklearn.preprocessing",
        "isExtraImport": true,
        "detail": "sklearn.preprocessing",
        "documentation": {}
    },
    {
        "label": "fbeta_score",
        "importPath": "sklearn.metrics",
        "description": "sklearn.metrics",
        "isExtraImport": true,
        "detail": "sklearn.metrics",
        "documentation": {}
    },
    {
        "label": "precision_score",
        "importPath": "sklearn.metrics",
        "description": "sklearn.metrics",
        "isExtraImport": true,
        "detail": "sklearn.metrics",
        "documentation": {}
    },
    {
        "label": "recall_score",
        "importPath": "sklearn.metrics",
        "description": "sklearn.metrics",
        "isExtraImport": true,
        "detail": "sklearn.metrics",
        "documentation": {}
    },
    {
        "label": "LogisticRegression",
        "importPath": "sklearn.linear_model",
        "description": "sklearn.linear_model",
        "isExtraImport": true,
        "detail": "sklearn.linear_model",
        "documentation": {}
    },
    {
        "label": "pickle",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "pickle",
        "description": "pickle",
        "detail": "pickle",
        "documentation": {}
    },
    {
        "label": "pandas",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "pandas",
        "description": "pandas",
        "detail": "pandas",
        "documentation": {}
    },
    {
        "label": "os",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "os",
        "description": "os",
        "detail": "os",
        "documentation": {}
    },
    {
        "label": "path",
        "importPath": "os",
        "description": "os",
        "isExtraImport": true,
        "detail": "os",
        "documentation": {}
    },
    {
        "label": "pytest",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "pytest",
        "description": "pytest",
        "detail": "pytest",
        "documentation": {}
    },
    {
        "label": "TestClient",
        "importPath": "fastapi.testclient",
        "description": "fastapi.testclient",
        "isExtraImport": true,
        "detail": "fastapi.testclient",
        "documentation": {}
    },
    {
        "label": "app",
        "importPath": "main",
        "description": "main",
        "isExtraImport": true,
        "detail": "main",
        "documentation": {}
    },
    {
        "label": "train_test_split",
        "importPath": "sklearn.model_selection",
        "description": "sklearn.model_selection",
        "isExtraImport": true,
        "detail": "sklearn.model_selection",
        "documentation": {}
    },
    {
        "label": "train_test_split",
        "importPath": "sklearn.model_selection",
        "description": "sklearn.model_selection",
        "isExtraImport": true,
        "detail": "sklearn.model_selection",
        "documentation": {}
    },
    {
        "label": "load_data",
        "importPath": "data",
        "description": "data",
        "isExtraImport": true,
        "detail": "data",
        "documentation": {}
    },
    {
        "label": "process_data",
        "importPath": "ml.data",
        "description": "ml.data",
        "isExtraImport": true,
        "detail": "ml.data",
        "documentation": {}
    },
    {
        "label": "train_model",
        "importPath": "ml.model",
        "description": "ml.model",
        "isExtraImport": true,
        "detail": "ml.model",
        "documentation": {}
    },
    {
        "label": "compute_model_metrics",
        "importPath": "ml.model",
        "description": "ml.model",
        "isExtraImport": true,
        "detail": "ml.model",
        "documentation": {}
    },
    {
        "label": "evaluate_model_on_column_slices",
        "importPath": "ml.model",
        "description": "ml.model",
        "isExtraImport": true,
        "detail": "ml.model",
        "documentation": {}
    },
    {
        "label": "inference",
        "importPath": "ml.model",
        "description": "ml.model",
        "isExtraImport": true,
        "detail": "ml.model",
        "documentation": {}
    },
    {
        "label": "save_model",
        "importPath": "ml.model",
        "description": "ml.model",
        "isExtraImport": true,
        "detail": "ml.model",
        "documentation": {}
    },
    {
        "label": "FastAPI",
        "importPath": "fastapi",
        "description": "fastapi",
        "isExtraImport": true,
        "detail": "fastapi",
        "documentation": {}
    },
    {
        "label": "BaseModel",
        "importPath": "pydantic",
        "description": "pydantic",
        "isExtraImport": true,
        "detail": "pydantic",
        "documentation": {}
    },
    {
        "label": "process_data",
        "importPath": "starter.ml.data",
        "description": "starter.ml.data",
        "isExtraImport": true,
        "detail": "starter.ml.data",
        "documentation": {}
    },
    {
        "label": "inference",
        "importPath": "starter.ml.model",
        "description": "starter.ml.model",
        "isExtraImport": true,
        "detail": "starter.ml.model",
        "documentation": {}
    },
    {
        "label": "load_model",
        "importPath": "starter.ml.model",
        "description": "starter.ml.model",
        "isExtraImport": true,
        "detail": "starter.ml.model",
        "documentation": {}
    },
    {
        "label": "argparse",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "argparse",
        "description": "argparse",
        "detail": "argparse",
        "documentation": {}
    },
    {
        "label": "importlib",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "importlib",
        "description": "importlib",
        "detail": "importlib",
        "documentation": {}
    },
    {
        "label": "inspect",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "inspect",
        "description": "inspect",
        "detail": "inspect",
        "documentation": {}
    },
    {
        "label": "sys",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "sys",
        "description": "sys",
        "detail": "sys",
        "documentation": {}
    },
    {
        "label": "setuptools",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "setuptools",
        "description": "setuptools",
        "detail": "setuptools",
        "documentation": {}
    },
    {
        "label": "json",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "json",
        "description": "json",
        "detail": "json",
        "documentation": {}
    },
    {
        "label": "requests",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "requests",
        "description": "requests",
        "detail": "requests",
        "documentation": {}
    },
    {
        "label": "process_data",
        "kind": 2,
        "importPath": "starter.starter.ml.data",
        "description": "starter.starter.ml.data",
        "peekOfCode": "def process_data(X, categorical_features=[], label=None, training=True, encoder=None, lb=None):\n    if label is not None:\n        y = X[label]\n        X = X.drop([label], axis=1)\n    else:\n        y = np.array([])\n    X_categorical = X[categorical_features].values\n    X_continuous = X.drop(*[categorical_features], axis=1)\n    if training is True:\n        encoder = OneHotEncoder(sparse=False, handle_unknown=\"ignore\")",
        "detail": "starter.starter.ml.data",
        "documentation": {}
    },
    {
        "label": "save_model",
        "kind": 2,
        "importPath": "starter.starter.ml.model",
        "description": "starter.starter.ml.model",
        "peekOfCode": "def save_model(model, file):\n    \"\"\"\n    save_model: saves a pickled model to a file.\n    Args:\n        model: The model to save\n        file: The file to save the model to.\n    \"\"\"\n    with open(file, \"wb\") as f:\n        pickle.dump(model, f)\n# load the model",
        "detail": "starter.starter.ml.model",
        "documentation": {}
    },
    {
        "label": "load_model",
        "kind": 2,
        "importPath": "starter.starter.ml.model",
        "description": "starter.starter.ml.model",
        "peekOfCode": "def load_model(file):\n    \"\"\"\n    load_model: loads a pickled model from a file.\n    Args:\n        file: The file to load the model from.\n    Returns:\n        model: logistic regression model\n    \"\"\"\n    with open(file, \"rb\") as f:\n        model = pickle.load(f)",
        "detail": "starter.starter.ml.model",
        "documentation": {}
    },
    {
        "label": "train_model",
        "kind": 2,
        "importPath": "starter.starter.ml.model",
        "description": "starter.starter.ml.model",
        "peekOfCode": "def train_model(X_train, y_train):\n    \"\"\"\n    Trains a machine learning model and returns it.\n    Inputs\n    ------\n    X_train : np.array\n        Training data.\n    y_train : np.array\n        Labels.\n    Returns",
        "detail": "starter.starter.ml.model",
        "documentation": {}
    },
    {
        "label": "compute_model_metrics",
        "kind": 2,
        "importPath": "starter.starter.ml.model",
        "description": "starter.starter.ml.model",
        "peekOfCode": "def compute_model_metrics(y, predictions):\n    \"\"\"\n    Validates the trained machine learning model using precision, recall, and F1.\n    Inputs\n    ------\n    y : np.array\n        Known labels, binarized.\n    preds : np.array\n        Predicted labels, binarized.\n    Returns",
        "detail": "starter.starter.ml.model",
        "documentation": {}
    },
    {
        "label": "inference",
        "kind": 2,
        "importPath": "starter.starter.ml.model",
        "description": "starter.starter.ml.model",
        "peekOfCode": "def inference(model, X):\n    \"\"\" Run model inferences and return the predictions.\n    Inputs\n    ------\n    model : sklearn model\n        Trained machine learning model.\n    X : np.array\n        Data used for prediction.\n    Returns\n    -------",
        "detail": "starter.starter.ml.model",
        "documentation": {}
    },
    {
        "label": "evaluate_model_on_column_slices",
        "kind": 2,
        "importPath": "starter.starter.ml.model",
        "description": "starter.starter.ml.model",
        "peekOfCode": "def evaluate_model_on_column_slices(df, column, y, predictions):\n    \"\"\"\n    Validates the trained machine learning model on column slices\n    using precision, recall, and F1.\n    Inputs\n    ------\n    df: pd.DataFrame\n        Test dataset used for creating predictions\n    column: str\n        Column name to create slices on",
        "detail": "starter.starter.ml.model",
        "documentation": {}
    },
    {
        "label": "RANDOM_STATE",
        "kind": 5,
        "importPath": "starter.starter.ml.model",
        "description": "starter.starter.ml.model",
        "peekOfCode": "RANDOM_STATE = 42\n# save the model\ndef save_model(model, file):\n    \"\"\"\n    save_model: saves a pickled model to a file.\n    Args:\n        model: The model to save\n        file: The file to save the model to.\n    \"\"\"\n    with open(file, \"wb\") as f:",
        "detail": "starter.starter.ml.model",
        "documentation": {}
    },
    {
        "label": "clean_data",
        "kind": 2,
        "importPath": "starter.starter.data",
        "description": "starter.starter.data",
        "peekOfCode": "def clean_data(df):\n    df.replace({'?': None}, inplace=True)\n    df.dropna(inplace=True)\n    df.drop([\"capital-gain\", \"capital-loss\", \"education-num\", \"fnlgt\"], axis=\"columns\", inplace=True)\n    return df\ndef load_data(path):\n    return pd.read_csv(path, skipinitialspace=True)\ndef save_data(df, path):\n    return df.to_csv(path, index=False)\nif __name__ == \"__main__\":",
        "detail": "starter.starter.data",
        "documentation": {}
    },
    {
        "label": "load_data",
        "kind": 2,
        "importPath": "starter.starter.data",
        "description": "starter.starter.data",
        "peekOfCode": "def load_data(path):\n    return pd.read_csv(path, skipinitialspace=True)\ndef save_data(df, path):\n    return df.to_csv(path, index=False)\nif __name__ == \"__main__\":\n    dir = \"../data/\"\n    load_path = os.path.join(dir, \"census.csv\")\n    df = load_data(load_path)\n    clean_df = clean_data(df)\n    save_path = os.path.join(dir, \"census_clean.csv\")",
        "detail": "starter.starter.data",
        "documentation": {}
    },
    {
        "label": "save_data",
        "kind": 2,
        "importPath": "starter.starter.data",
        "description": "starter.starter.data",
        "peekOfCode": "def save_data(df, path):\n    return df.to_csv(path, index=False)\nif __name__ == \"__main__\":\n    dir = \"../data/\"\n    load_path = os.path.join(dir, \"census.csv\")\n    df = load_data(load_path)\n    clean_df = clean_data(df)\n    save_path = os.path.join(dir, \"census_clean.csv\")\n    save_data(clean_df, save_path)",
        "detail": "starter.starter.data",
        "documentation": {}
    },
    {
        "label": "test_main_route_OK",
        "kind": 2,
        "importPath": "starter.starter.test_api",
        "description": "starter.starter.test_api",
        "peekOfCode": "def test_main_route_OK():\n    route = client.get(\"/\")\n    assert route.status_code == 200\ndef test_main_route_message():\n    route = client.get(\"/\")\n    assert route.json() == \"Greetings!!!\"",
        "detail": "starter.starter.test_api",
        "documentation": {}
    },
    {
        "label": "test_main_route_message",
        "kind": 2,
        "importPath": "starter.starter.test_api",
        "description": "starter.starter.test_api",
        "peekOfCode": "def test_main_route_message():\n    route = client.get(\"/\")\n    assert route.json() == \"Greetings!!!\"",
        "detail": "starter.starter.test_api",
        "documentation": {}
    },
    {
        "label": "client",
        "kind": 5,
        "importPath": "starter.starter.test_api",
        "description": "starter.starter.test_api",
        "peekOfCode": "client = TestClient(app)\ndef test_main_route_OK():\n    route = client.get(\"/\")\n    assert route.status_code == 200\ndef test_main_route_message():\n    route = client.get(\"/\")\n    assert route.json() == \"Greetings!!!\"",
        "detail": "starter.starter.test_api",
        "documentation": {}
    },
    {
        "label": "root",
        "kind": 2,
        "importPath": "starter.starter.test_model",
        "description": "starter.starter.test_model",
        "peekOfCode": "def root(): # root directory\n    return os.getcwd()\n@pytest.fixture\ndef files(root):\n    load_path = os.path.join(root, \"starter/data/census_cleaned.csv\")\n    data = load_data(load_path)\n    #data = pd.read_csv(\"../data/census.csv\")\n    model = os.path.join(root, model_dir, \"lr_model.pkl\")\n    with open(model, \"rb\") as f:\n        model = pickle.load(f)",
        "detail": "starter.starter.test_model",
        "documentation": {}
    },
    {
        "label": "files",
        "kind": 2,
        "importPath": "starter.starter.test_model",
        "description": "starter.starter.test_model",
        "peekOfCode": "def files(root):\n    load_path = os.path.join(root, \"starter/data/census_cleaned.csv\")\n    data = load_data(load_path)\n    #data = pd.read_csv(\"../data/census.csv\")\n    model = os.path.join(root, model_dir, \"lr_model.pkl\")\n    with open(model, \"rb\") as f:\n        model = pickle.load(f)\n    encoder = os.path.join(root, model_dir, \"encoder.pkl\")\n    with open(encoder, \"rb\") as f:\n        encoder = pickle.load(f)",
        "detail": "starter.starter.test_model",
        "documentation": {}
    },
    {
        "label": "train_test_data",
        "kind": 2,
        "importPath": "starter.starter.test_model",
        "description": "starter.starter.test_model",
        "peekOfCode": "def train_test_data(files):\n    data, model, encoder, lb = files\n    train, test = train_test_split(data, test_size=0.20, random_state=42)\n    return train, test\ndef test_train_model(files, root):\n    data, model, encoder, lb = files\n    train, test = train_test_split(data, test_size=0.20)\n    cat_features = [\n        \"workclass\",\n        \"education\",",
        "detail": "starter.starter.test_model",
        "documentation": {}
    },
    {
        "label": "test_train_model",
        "kind": 2,
        "importPath": "starter.starter.test_model",
        "description": "starter.starter.test_model",
        "peekOfCode": "def test_train_model(files, root):\n    data, model, encoder, lb = files\n    train, test = train_test_split(data, test_size=0.20)\n    cat_features = [\n        \"workclass\",\n        \"education\",\n        \"marital-status\",\n        \"occupation\",\n        \"relationship\",\n        \"race\",",
        "detail": "starter.starter.test_model",
        "documentation": {}
    },
    {
        "label": "data_dir",
        "kind": 5,
        "importPath": "starter.starter.test_model",
        "description": "starter.starter.test_model",
        "peekOfCode": "data_dir = \"data/\"\nmodel_dir = \"model/\"\n@pytest.fixture \ndef root(): # root directory\n    return os.getcwd()\n@pytest.fixture\ndef files(root):\n    load_path = os.path.join(root, \"starter/data/census_cleaned.csv\")\n    data = load_data(load_path)\n    #data = pd.read_csv(\"../data/census.csv\")",
        "detail": "starter.starter.test_model",
        "documentation": {}
    },
    {
        "label": "model_dir",
        "kind": 5,
        "importPath": "starter.starter.test_model",
        "description": "starter.starter.test_model",
        "peekOfCode": "model_dir = \"model/\"\n@pytest.fixture \ndef root(): # root directory\n    return os.getcwd()\n@pytest.fixture\ndef files(root):\n    load_path = os.path.join(root, \"starter/data/census_cleaned.csv\")\n    data = load_data(load_path)\n    #data = pd.read_csv(\"../data/census.csv\")\n    model = os.path.join(root, model_dir, \"lr_model.pkl\")",
        "detail": "starter.starter.test_model",
        "documentation": {}
    },
    {
        "label": "data_dir",
        "kind": 5,
        "importPath": "starter.starter.train_model",
        "description": "starter.starter.train_model",
        "peekOfCode": "data_dir = \"../data/\"   # the directory where the data is stored.\ndata_path = os.path.join(data_dir + \"census_clean.csv\") # path to the clean data\ndata = load_data(data_path)\n# Optional enhancement, use K-fold cross validation instead of a train-test split.\ntrain, test = train_test_split(data, test_size=0.20)    # 20% of the data will be used for testing\ncat_features = [\n    \"workclass\",\n    \"education\",\n    \"marital-status\",\n    \"occupation\",",
        "detail": "starter.starter.train_model",
        "documentation": {}
    },
    {
        "label": "data_path",
        "kind": 5,
        "importPath": "starter.starter.train_model",
        "description": "starter.starter.train_model",
        "peekOfCode": "data_path = os.path.join(data_dir + \"census_clean.csv\") # path to the clean data\ndata = load_data(data_path)\n# Optional enhancement, use K-fold cross validation instead of a train-test split.\ntrain, test = train_test_split(data, test_size=0.20)    # 20% of the data will be used for testing\ncat_features = [\n    \"workclass\",\n    \"education\",\n    \"marital-status\",\n    \"occupation\",\n    \"relationship\",",
        "detail": "starter.starter.train_model",
        "documentation": {}
    },
    {
        "label": "data",
        "kind": 5,
        "importPath": "starter.starter.train_model",
        "description": "starter.starter.train_model",
        "peekOfCode": "data = load_data(data_path)\n# Optional enhancement, use K-fold cross validation instead of a train-test split.\ntrain, test = train_test_split(data, test_size=0.20)    # 20% of the data will be used for testing\ncat_features = [\n    \"workclass\",\n    \"education\",\n    \"marital-status\",\n    \"occupation\",\n    \"relationship\",\n    \"race\",",
        "detail": "starter.starter.train_model",
        "documentation": {}
    },
    {
        "label": "cat_features",
        "kind": 5,
        "importPath": "starter.starter.train_model",
        "description": "starter.starter.train_model",
        "peekOfCode": "cat_features = [\n    \"workclass\",\n    \"education\",\n    \"marital-status\",\n    \"occupation\",\n    \"relationship\",\n    \"race\",\n    \"sex\",\n    \"native-country\",\n]   ",
        "detail": "starter.starter.train_model",
        "documentation": {}
    },
    {
        "label": "model_dir",
        "kind": 5,
        "importPath": "starter.starter.train_model",
        "description": "starter.starter.train_model",
        "peekOfCode": "model_dir = \"../model/\"  # the directory where the model will be stored.\nsave_model(encoder, os.path.join(model_dir, \"encoder.pkl\")) # save the label encoder\nsave_model(lb, os.path.join(model_dir, \"lb.pkl\")) # save the encoder\nmodel_path = os.path.join(model_dir, \"lr_model.pkl\") # path to the model\nslice_output = os.path.join(model_dir,'/slice_output.txt') # path to the slice output\n# Process the test data with the process_data function.\nX_test, y_test, encoder, lb = process_data(\n    test, categorical_features=cat_features, label=\"salary\", training=False, encoder=encoder, lb=lb)    # load the encoder and label encoder\n# Train and save a model.\nclassifier = train_model(X_train, y_train)  # train the model",
        "detail": "starter.starter.train_model",
        "documentation": {}
    },
    {
        "label": "model_path",
        "kind": 5,
        "importPath": "starter.starter.train_model",
        "description": "starter.starter.train_model",
        "peekOfCode": "model_path = os.path.join(model_dir, \"lr_model.pkl\") # path to the model\nslice_output = os.path.join(model_dir,'/slice_output.txt') # path to the slice output\n# Process the test data with the process_data function.\nX_test, y_test, encoder, lb = process_data(\n    test, categorical_features=cat_features, label=\"salary\", training=False, encoder=encoder, lb=lb)    # load the encoder and label encoder\n# Train and save a model.\nclassifier = train_model(X_train, y_train)  # train the model\nsave_model(classifier, model_path)\ny_train_predict = inference(classifier, X_train)    # make predictions on the training data\ntrain_precision, train_recall, train_fbeta = compute_model_metrics(y_train, y_train_predict)    # compute the metrics for the training data",
        "detail": "starter.starter.train_model",
        "documentation": {}
    },
    {
        "label": "slice_output",
        "kind": 5,
        "importPath": "starter.starter.train_model",
        "description": "starter.starter.train_model",
        "peekOfCode": "slice_output = os.path.join(model_dir,'/slice_output.txt') # path to the slice output\n# Process the test data with the process_data function.\nX_test, y_test, encoder, lb = process_data(\n    test, categorical_features=cat_features, label=\"salary\", training=False, encoder=encoder, lb=lb)    # load the encoder and label encoder\n# Train and save a model.\nclassifier = train_model(X_train, y_train)  # train the model\nsave_model(classifier, model_path)\ny_train_predict = inference(classifier, X_train)    # make predictions on the training data\ntrain_precision, train_recall, train_fbeta = compute_model_metrics(y_train, y_train_predict)    # compute the metrics for the training data\nprint(f\"train_precision: {train_precision}, train_recall: {train_recall}, train_fbeta: {train_fbeta}\")  # print the metrics for the training data",
        "detail": "starter.starter.train_model",
        "documentation": {}
    },
    {
        "label": "classifier",
        "kind": 5,
        "importPath": "starter.starter.train_model",
        "description": "starter.starter.train_model",
        "peekOfCode": "classifier = train_model(X_train, y_train)  # train the model\nsave_model(classifier, model_path)\ny_train_predict = inference(classifier, X_train)    # make predictions on the training data\ntrain_precision, train_recall, train_fbeta = compute_model_metrics(y_train, y_train_predict)    # compute the metrics for the training data\nprint(f\"train_precision: {train_precision}, train_recall: {train_recall}, train_fbeta: {train_fbeta}\")  # print the metrics for the training data\ny_test_predict = inference(classifier, X_test)  # make predictions on the test data\ntest_precision, test_recall, test_fbeta = compute_model_metrics(y_test, y_test_predict) # compute the metrics for the test data\nprint(f\"test_precision: {test_precision}, test_recall: {test_recall}, test_fbeta: {test_fbeta}\")    # print the metrics for the test data\nslice_metrics = evaluate_model_on_column_slices(test, 'education', y_test, y_test_predict)\nmetric_df = pd.DataFrame(slice_metrics, columns=['education_slice', 'precision', 'recall', 'f1'])",
        "detail": "starter.starter.train_model",
        "documentation": {}
    },
    {
        "label": "y_train_predict",
        "kind": 5,
        "importPath": "starter.starter.train_model",
        "description": "starter.starter.train_model",
        "peekOfCode": "y_train_predict = inference(classifier, X_train)    # make predictions on the training data\ntrain_precision, train_recall, train_fbeta = compute_model_metrics(y_train, y_train_predict)    # compute the metrics for the training data\nprint(f\"train_precision: {train_precision}, train_recall: {train_recall}, train_fbeta: {train_fbeta}\")  # print the metrics for the training data\ny_test_predict = inference(classifier, X_test)  # make predictions on the test data\ntest_precision, test_recall, test_fbeta = compute_model_metrics(y_test, y_test_predict) # compute the metrics for the test data\nprint(f\"test_precision: {test_precision}, test_recall: {test_recall}, test_fbeta: {test_fbeta}\")    # print the metrics for the test data\nslice_metrics = evaluate_model_on_column_slices(test, 'education', y_test, y_test_predict)\nmetric_df = pd.DataFrame(slice_metrics, columns=['education_slice', 'precision', 'recall', 'f1'])\nmetric_df.to_csv('../model/slice_output.txt', index=False)",
        "detail": "starter.starter.train_model",
        "documentation": {}
    },
    {
        "label": "y_test_predict",
        "kind": 5,
        "importPath": "starter.starter.train_model",
        "description": "starter.starter.train_model",
        "peekOfCode": "y_test_predict = inference(classifier, X_test)  # make predictions on the test data\ntest_precision, test_recall, test_fbeta = compute_model_metrics(y_test, y_test_predict) # compute the metrics for the test data\nprint(f\"test_precision: {test_precision}, test_recall: {test_recall}, test_fbeta: {test_fbeta}\")    # print the metrics for the test data\nslice_metrics = evaluate_model_on_column_slices(test, 'education', y_test, y_test_predict)\nmetric_df = pd.DataFrame(slice_metrics, columns=['education_slice', 'precision', 'recall', 'f1'])\nmetric_df.to_csv('../model/slice_output.txt', index=False)",
        "detail": "starter.starter.train_model",
        "documentation": {}
    },
    {
        "label": "slice_metrics",
        "kind": 5,
        "importPath": "starter.starter.train_model",
        "description": "starter.starter.train_model",
        "peekOfCode": "slice_metrics = evaluate_model_on_column_slices(test, 'education', y_test, y_test_predict)\nmetric_df = pd.DataFrame(slice_metrics, columns=['education_slice', 'precision', 'recall', 'f1'])\nmetric_df.to_csv('../model/slice_output.txt', index=False)",
        "detail": "starter.starter.train_model",
        "documentation": {}
    },
    {
        "label": "metric_df",
        "kind": 5,
        "importPath": "starter.starter.train_model",
        "description": "starter.starter.train_model",
        "peekOfCode": "metric_df = pd.DataFrame(slice_metrics, columns=['education_slice', 'precision', 'recall', 'f1'])\nmetric_df.to_csv('../model/slice_output.txt', index=False)",
        "detail": "starter.starter.train_model",
        "documentation": {}
    },
    {
        "label": "Data",
        "kind": 6,
        "importPath": "starter.main",
        "description": "starter.main",
        "peekOfCode": "class Data(BaseModel):\n    age: int\n    workclass: str\n    fnlgt: int\n    education: str\n    education_num: int\n    marital_status: str\n    occupation: str\n    relationship: str\n    race: str",
        "detail": "starter.main",
        "documentation": {}
    },
    {
        "label": "greetings",
        "kind": 2,
        "importPath": "starter.main",
        "description": "starter.main",
        "peekOfCode": "def greetings():\n    \"\"\"\n    greetings route\n    Returns:\n        string: a greetings message\n    \"\"\"\n    return \"Greetings!!!\"\n@app.post(\"/inference/\")  # greetings route\ndef inference_route(data: Data):\n    \"\"\"",
        "detail": "starter.main",
        "documentation": {}
    },
    {
        "label": "inference_route",
        "kind": 2,
        "importPath": "starter.main",
        "description": "starter.main",
        "peekOfCode": "def inference_route(data: Data):\n    \"\"\"\n    inference_route [summary]\n    [extended_summary]\n    Args:\n        data (Data):  base model for data\n    Returns:\n        float: prediction\n    \"\"\"\n    dictionary = {",
        "detail": "starter.main",
        "documentation": {}
    },
    {
        "label": "categorical_features",
        "kind": 5,
        "importPath": "starter.main",
        "description": "starter.main",
        "peekOfCode": "categorical_features = [\n    \"workclass\",\n    \"education\",\n    \"marital-status\",\n    \"occupation\",\n    \"relationship\",\n    \"race\",\n    \"sex\",\n    \"native-country\",\n]",
        "detail": "starter.main",
        "documentation": {}
    },
    {
        "label": "app",
        "kind": 5,
        "importPath": "starter.main",
        "description": "starter.main",
        "peekOfCode": "app = FastAPI()  # initialize the application\nclass Data(BaseModel):\n    age: int\n    workclass: str\n    fnlgt: int\n    education: str\n    education_num: int\n    marital_status: str\n    occupation: str\n    relationship: str",
        "detail": "starter.main",
        "documentation": {}
    },
    {
        "label": "run_sanity_check",
        "kind": 2,
        "importPath": "starter.sanitycheck",
        "description": "starter.sanitycheck",
        "peekOfCode": "def run_sanity_check(test_dir):\n    #assert path.isdir(test_dir), FAIL_COLOR+f\"No direcotry named {test_dir} found in {os.getcwd()}\"\n    print('This script will perform a sanity test to ensure your code meets the criteria in the rubric.\\n')\n    print('Please enter the path to the file that contains your test cases for the GET() and POST() methods')\n    print('The path should be something like abc/def/test_xyz.py')\n    filepath = input('> ')\n    assert path.exists(filepath), f\"File {filepath} does not exist.\"\n    sys.path.append(path.dirname(filepath))\n    module_name = path.splitext(path.basename(filepath))[0]\n    module = importlib.import_module(module_name)",
        "detail": "starter.sanitycheck",
        "documentation": {}
    },
    {
        "label": "FAIL_COLOR",
        "kind": 5,
        "importPath": "starter.sanitycheck",
        "description": "starter.sanitycheck",
        "peekOfCode": "FAIL_COLOR = '\\033[91m'\nOK_COLOR = '\\033[92m'\nWARN_COLOR = '\\033[93m'\ndef run_sanity_check(test_dir):\n    #assert path.isdir(test_dir), FAIL_COLOR+f\"No direcotry named {test_dir} found in {os.getcwd()}\"\n    print('This script will perform a sanity test to ensure your code meets the criteria in the rubric.\\n')\n    print('Please enter the path to the file that contains your test cases for the GET() and POST() methods')\n    print('The path should be something like abc/def/test_xyz.py')\n    filepath = input('> ')\n    assert path.exists(filepath), f\"File {filepath} does not exist.\"",
        "detail": "starter.sanitycheck",
        "documentation": {}
    },
    {
        "label": "OK_COLOR",
        "kind": 5,
        "importPath": "starter.sanitycheck",
        "description": "starter.sanitycheck",
        "peekOfCode": "OK_COLOR = '\\033[92m'\nWARN_COLOR = '\\033[93m'\ndef run_sanity_check(test_dir):\n    #assert path.isdir(test_dir), FAIL_COLOR+f\"No direcotry named {test_dir} found in {os.getcwd()}\"\n    print('This script will perform a sanity test to ensure your code meets the criteria in the rubric.\\n')\n    print('Please enter the path to the file that contains your test cases for the GET() and POST() methods')\n    print('The path should be something like abc/def/test_xyz.py')\n    filepath = input('> ')\n    assert path.exists(filepath), f\"File {filepath} does not exist.\"\n    sys.path.append(path.dirname(filepath))",
        "detail": "starter.sanitycheck",
        "documentation": {}
    },
    {
        "label": "WARN_COLOR",
        "kind": 5,
        "importPath": "starter.sanitycheck",
        "description": "starter.sanitycheck",
        "peekOfCode": "WARN_COLOR = '\\033[93m'\ndef run_sanity_check(test_dir):\n    #assert path.isdir(test_dir), FAIL_COLOR+f\"No direcotry named {test_dir} found in {os.getcwd()}\"\n    print('This script will perform a sanity test to ensure your code meets the criteria in the rubric.\\n')\n    print('Please enter the path to the file that contains your test cases for the GET() and POST() methods')\n    print('The path should be something like abc/def/test_xyz.py')\n    filepath = input('> ')\n    assert path.exists(filepath), f\"File {filepath} does not exist.\"\n    sys.path.append(path.dirname(filepath))\n    module_name = path.splitext(path.basename(filepath))[0]",
        "detail": "starter.sanitycheck",
        "documentation": {}
    },
    {
        "label": "PREDICT_URI",
        "kind": 5,
        "importPath": "api",
        "description": "api",
        "peekOfCode": "PREDICT_URI = \"https://udacity-mlops-nanodegree-app.herokuapp.com/predict\"\nsample = {\n    'age': 42,\n    'workclass': 'Private',\n    'fnlgt': 159449,\n    'education': 'Bachelors',\n    'education-num': 13,\n    'marital-status': 'Married-civ-spouse',\n    'occupation': 'Exec-managerial',\n    'relationship': 'Husband',",
        "detail": "api",
        "documentation": {}
    },
    {
        "label": "sample",
        "kind": 5,
        "importPath": "api",
        "description": "api",
        "peekOfCode": "sample = {\n    'age': 42,\n    'workclass': 'Private',\n    'fnlgt': 159449,\n    'education': 'Bachelors',\n    'education-num': 13,\n    'marital-status': 'Married-civ-spouse',\n    'occupation': 'Exec-managerial',\n    'relationship': 'Husband',\n    'race': 'White',",
        "detail": "api",
        "documentation": {}
    },
    {
        "label": "request",
        "kind": 5,
        "importPath": "api",
        "description": "api",
        "peekOfCode": "request = requests.post(PREDICT_URI, json=sample)\nassert request.status_code == 200\nassert request.json() == {\"prediction\": 1}\ndictionary = {\n    'Request body': sample,\n    'Status code': request.status_code,\n    'Response': request.json()\n}\nprint(json.dumps(dictionary, indent=4))",
        "detail": "api",
        "documentation": {}
    },
    {
        "label": "dictionary",
        "kind": 5,
        "importPath": "api",
        "description": "api",
        "peekOfCode": "dictionary = {\n    'Request body': sample,\n    'Status code': request.status_code,\n    'Response': request.json()\n}\nprint(json.dumps(dictionary, indent=4))",
        "detail": "api",
        "documentation": {}
    }
]