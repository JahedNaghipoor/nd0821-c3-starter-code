[
    {
        "label": "numpy",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "numpy",
        "description": "numpy",
        "detail": "numpy",
        "documentation": {}
    },
    {
        "label": "LabelBinarizer",
        "importPath": "sklearn.preprocessing",
        "description": "sklearn.preprocessing",
        "isExtraImport": true,
        "detail": "sklearn.preprocessing",
        "documentation": {}
    },
    {
        "label": "OneHotEncoder",
        "importPath": "sklearn.preprocessing",
        "description": "sklearn.preprocessing",
        "isExtraImport": true,
        "detail": "sklearn.preprocessing",
        "documentation": {}
    },
    {
        "label": "fbeta_score",
        "importPath": "sklearn.metrics",
        "description": "sklearn.metrics",
        "isExtraImport": true,
        "detail": "sklearn.metrics",
        "documentation": {}
    },
    {
        "label": "precision_score",
        "importPath": "sklearn.metrics",
        "description": "sklearn.metrics",
        "isExtraImport": true,
        "detail": "sklearn.metrics",
        "documentation": {}
    },
    {
        "label": "recall_score",
        "importPath": "sklearn.metrics",
        "description": "sklearn.metrics",
        "isExtraImport": true,
        "detail": "sklearn.metrics",
        "documentation": {}
    },
    {
        "label": "RandomForestClassifier",
        "importPath": "sklearn.ensemble",
        "description": "sklearn.ensemble",
        "isExtraImport": true,
        "detail": "sklearn.ensemble",
        "documentation": {}
    },
    {
        "label": "RandomForestClassifier",
        "importPath": "sklearn.ensemble",
        "description": "sklearn.ensemble",
        "isExtraImport": true,
        "detail": "sklearn.ensemble",
        "documentation": {}
    },
    {
        "label": "pickle",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "pickle",
        "description": "pickle",
        "detail": "pickle",
        "documentation": {}
    },
    {
        "label": "pandas",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "pandas",
        "description": "pandas",
        "detail": "pandas",
        "documentation": {}
    },
    {
        "label": "os",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "os",
        "description": "os",
        "detail": "os",
        "documentation": {}
    },
    {
        "label": "path",
        "importPath": "os",
        "description": "os",
        "isExtraImport": true,
        "detail": "os",
        "documentation": {}
    },
    {
        "label": "pytest",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "pytest",
        "description": "pytest",
        "detail": "pytest",
        "documentation": {}
    },
    {
        "label": "TestClient",
        "importPath": "fastapi.testclient",
        "description": "fastapi.testclient",
        "isExtraImport": true,
        "detail": "fastapi.testclient",
        "documentation": {}
    },
    {
        "label": "app",
        "importPath": "main",
        "description": "main",
        "isExtraImport": true,
        "detail": "main",
        "documentation": {}
    },
    {
        "label": "train_model",
        "importPath": "ml.model",
        "description": "ml.model",
        "isExtraImport": true,
        "detail": "ml.model",
        "documentation": {}
    },
    {
        "label": "inference",
        "importPath": "ml.model",
        "description": "ml.model",
        "isExtraImport": true,
        "detail": "ml.model",
        "documentation": {}
    },
    {
        "label": "compute_model_metrics",
        "importPath": "ml.model",
        "description": "ml.model",
        "isExtraImport": true,
        "detail": "ml.model",
        "documentation": {}
    },
    {
        "label": "train_model",
        "importPath": "ml.model",
        "description": "ml.model",
        "isExtraImport": true,
        "detail": "ml.model",
        "documentation": {}
    },
    {
        "label": "compute_model_metrics",
        "importPath": "ml.model",
        "description": "ml.model",
        "isExtraImport": true,
        "detail": "ml.model",
        "documentation": {}
    },
    {
        "label": "evaluate_model_on_column_slices",
        "importPath": "ml.model",
        "description": "ml.model",
        "isExtraImport": true,
        "detail": "ml.model",
        "documentation": {}
    },
    {
        "label": "inference",
        "importPath": "ml.model",
        "description": "ml.model",
        "isExtraImport": true,
        "detail": "ml.model",
        "documentation": {}
    },
    {
        "label": "save_model",
        "importPath": "ml.model",
        "description": "ml.model",
        "isExtraImport": true,
        "detail": "ml.model",
        "documentation": {}
    },
    {
        "label": "inference",
        "importPath": "ml.model",
        "description": "ml.model",
        "isExtraImport": true,
        "detail": "ml.model",
        "documentation": {}
    },
    {
        "label": "load_model",
        "importPath": "ml.model",
        "description": "ml.model",
        "isExtraImport": true,
        "detail": "ml.model",
        "documentation": {}
    },
    {
        "label": "train_test_split",
        "importPath": "sklearn.model_selection",
        "description": "sklearn.model_selection",
        "isExtraImport": true,
        "detail": "sklearn.model_selection",
        "documentation": {}
    },
    {
        "label": "load_data",
        "importPath": "data",
        "description": "data",
        "isExtraImport": true,
        "detail": "data",
        "documentation": {}
    },
    {
        "label": "process_data",
        "importPath": "ml.data",
        "description": "ml.data",
        "isExtraImport": true,
        "detail": "ml.data",
        "documentation": {}
    },
    {
        "label": "process_data",
        "importPath": "ml.data",
        "description": "ml.data",
        "isExtraImport": true,
        "detail": "ml.data",
        "documentation": {}
    },
    {
        "label": "Body",
        "importPath": "fastapi",
        "description": "fastapi",
        "isExtraImport": true,
        "detail": "fastapi",
        "documentation": {}
    },
    {
        "label": "FastAPI",
        "importPath": "fastapi",
        "description": "fastapi",
        "isExtraImport": true,
        "detail": "fastapi",
        "documentation": {}
    },
    {
        "label": "BaseModel",
        "importPath": "pydantic",
        "description": "pydantic",
        "isExtraImport": true,
        "detail": "pydantic",
        "documentation": {}
    },
    {
        "label": "argparse",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "argparse",
        "description": "argparse",
        "detail": "argparse",
        "documentation": {}
    },
    {
        "label": "importlib",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "importlib",
        "description": "importlib",
        "detail": "importlib",
        "documentation": {}
    },
    {
        "label": "inspect",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "inspect",
        "description": "inspect",
        "detail": "inspect",
        "documentation": {}
    },
    {
        "label": "sys",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "sys",
        "description": "sys",
        "detail": "sys",
        "documentation": {}
    },
    {
        "label": "setuptools",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "setuptools",
        "description": "setuptools",
        "detail": "setuptools",
        "documentation": {}
    },
    {
        "label": "json",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "json",
        "description": "json",
        "detail": "json",
        "documentation": {}
    },
    {
        "label": "requests",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "requests",
        "description": "requests",
        "detail": "requests",
        "documentation": {}
    },
    {
        "label": "process_data",
        "kind": 2,
        "importPath": "starter.starter.ml.data",
        "description": "starter.starter.ml.data",
        "peekOfCode": "def process_data(X, categorical_features=[], label=None, training=True, encoder=None, lb=None):\n    if label is not None:\n        y = X[label]\n        X = X.drop([label], axis=1)\n    else:\n        y = np.array([])\n    X_categorical = X[categorical_features].values\n    X_continuous = X.drop(*[categorical_features], axis=1)\n    if training is True:\n        encoder = OneHotEncoder(sparse=False, handle_unknown=\"ignore\")",
        "detail": "starter.starter.ml.data",
        "documentation": {}
    },
    {
        "label": "save_model",
        "kind": 2,
        "importPath": "starter.starter.ml.model",
        "description": "starter.starter.ml.model",
        "peekOfCode": "def save_model(model, file):\n    \"\"\"\n    save_model: saves a pickled model to a file.\n    Args:\n        model: The model to save\n        file: The file to save the model to.\n    \"\"\"\n    with open(file, \"wb\") as f:\n        pickle.dump(model, f)\n# load the model",
        "detail": "starter.starter.ml.model",
        "documentation": {}
    },
    {
        "label": "load_model",
        "kind": 2,
        "importPath": "starter.starter.ml.model",
        "description": "starter.starter.ml.model",
        "peekOfCode": "def load_model(file):\n    \"\"\"\n    load_model: loads a pickled model from a file.\n    Args:\n        file: The file to load the model from.\n    Returns:\n        model: logistic regression model\n    \"\"\"\n    with open(file, \"rb\") as f:\n        model = pickle.load(f)",
        "detail": "starter.starter.ml.model",
        "documentation": {}
    },
    {
        "label": "train_model",
        "kind": 2,
        "importPath": "starter.starter.ml.model",
        "description": "starter.starter.ml.model",
        "peekOfCode": "def train_model(X_train, y_train):\n    \"\"\"\n    Trains a machine learning model and returns it.\n    Inputs\n    ------\n    X_train : np.array\n        Training data.\n    y_train : np.array\n        Labels.\n    Returns",
        "detail": "starter.starter.ml.model",
        "documentation": {}
    },
    {
        "label": "compute_model_metrics",
        "kind": 2,
        "importPath": "starter.starter.ml.model",
        "description": "starter.starter.ml.model",
        "peekOfCode": "def compute_model_metrics(y, predictions):\n    \"\"\"\n    Validates the trained machine learning model using precision, recall, and F1.\n    Inputs\n    ------\n    y : np.array\n        Known labels, binarized.\n    preds : np.array\n        Predicted labels, binarized.\n    Returns",
        "detail": "starter.starter.ml.model",
        "documentation": {}
    },
    {
        "label": "inference",
        "kind": 2,
        "importPath": "starter.starter.ml.model",
        "description": "starter.starter.ml.model",
        "peekOfCode": "def inference(model, X):\n    \"\"\" Run model inferences and return the predictions.\n    Inputs\n    ------\n    model : sklearn model\n        Trained machine learning model.\n    X : np.array\n        Data used for prediction.\n    Returns\n    -------",
        "detail": "starter.starter.ml.model",
        "documentation": {}
    },
    {
        "label": "evaluate_model_on_column_slices",
        "kind": 2,
        "importPath": "starter.starter.ml.model",
        "description": "starter.starter.ml.model",
        "peekOfCode": "def evaluate_model_on_column_slices(df, column, y, predictions):\n    \"\"\"\n    Validates the trained machine learning model on column slices\n    using precision, recall, and F1.\n    Inputs\n    ------\n    df: pd.DataFrame\n        Test dataset used for creating predictions\n    column: str\n        Column name to create slices on",
        "detail": "starter.starter.ml.model",
        "documentation": {}
    },
    {
        "label": "RANDOM_STATE",
        "kind": 5,
        "importPath": "starter.starter.ml.model",
        "description": "starter.starter.ml.model",
        "peekOfCode": "RANDOM_STATE = 42\n# save the model\ndef save_model(model, file):\n    \"\"\"\n    save_model: saves a pickled model to a file.\n    Args:\n        model: The model to save\n        file: The file to save the model to.\n    \"\"\"\n    with open(file, \"wb\") as f:",
        "detail": "starter.starter.ml.model",
        "documentation": {}
    },
    {
        "label": "clean_data",
        "kind": 2,
        "importPath": "starter.starter.data",
        "description": "starter.starter.data",
        "peekOfCode": "def clean_data(df):\n    df.replace({'?': None}, inplace=True)\n    df.dropna(inplace=True)\n    return df\ndef load_data(path):\n    return pd.read_csv(path, skipinitialspace=True)\ndef save_data(df, path):\n    return df.to_csv(path, index=False)\nif __name__ == \"__main__\":\n    dir = \"../data/\"",
        "detail": "starter.starter.data",
        "documentation": {}
    },
    {
        "label": "load_data",
        "kind": 2,
        "importPath": "starter.starter.data",
        "description": "starter.starter.data",
        "peekOfCode": "def load_data(path):\n    return pd.read_csv(path, skipinitialspace=True)\ndef save_data(df, path):\n    return df.to_csv(path, index=False)\nif __name__ == \"__main__\":\n    dir = \"../data/\"\n    load_path = os.path.join(dir, \"census.csv\")\n    df = load_data(load_path)\n    clean_df = clean_data(df)\n    save_path = os.path.join(dir, \"census_clean.csv\")",
        "detail": "starter.starter.data",
        "documentation": {}
    },
    {
        "label": "save_data",
        "kind": 2,
        "importPath": "starter.starter.data",
        "description": "starter.starter.data",
        "peekOfCode": "def save_data(df, path):\n    return df.to_csv(path, index=False)\nif __name__ == \"__main__\":\n    dir = \"../data/\"\n    load_path = os.path.join(dir, \"census.csv\")\n    df = load_data(load_path)\n    clean_df = clean_data(df)\n    save_path = os.path.join(dir, \"census_clean.csv\")\n    save_data(clean_df, save_path)",
        "detail": "starter.starter.data",
        "documentation": {}
    },
    {
        "label": "greater_than_fifty_sample",
        "kind": 2,
        "importPath": "starter.starter.test_api",
        "description": "starter.starter.test_api",
        "peekOfCode": "def greater_than_fifty_sample():\n    sample = {\n        \"age\": 52,\n        \"workclass\": \"Self-emp-inc\",\n        \"fnlgt\": 287927,\n        \"education\": \"HS-grad\",\n        \"education_num\": 9,\n        \"marital_status\": \"Married-civ-spouse\",\n        \"occupation\": \"Exec-managerial\",\n        \"relationship\": \"Wife\",",
        "detail": "starter.starter.test_api",
        "documentation": {}
    },
    {
        "label": "less_than_fifty_sample",
        "kind": 2,
        "importPath": "starter.starter.test_api",
        "description": "starter.starter.test_api",
        "peekOfCode": "def less_than_fifty_sample():\n    sample = {\n        \"age\": 39,\n        \"workclass\": \"State-gov\",\n        \"fnlgt\": 77516,\n        \"education\": \"Bachelors\",\n        \"education_num\": 13,\n        \"marital_status\": \"Never-married\",\n        \"occupation\": \"Adm-clerical\",\n        \"relationship\": \"Not-in-family\",",
        "detail": "starter.starter.test_api",
        "documentation": {}
    },
    {
        "label": "test_route",
        "kind": 2,
        "importPath": "starter.starter.test_api",
        "description": "starter.starter.test_api",
        "peekOfCode": "def test_route():\n    \"\"\"\n    test_route tests the route /\n    \"\"\"\n    r = client.get(\"/\")\n    assert r.status_code == 200\n    assert r.json() == \"Greetings!!!\"\ndef test_post_greater_than_fifty(greater_than_fifty_sample):\n    \"\"\"\n    test_post_greater_than_fifty tests the route /predict for the greater than 50K sample",
        "detail": "starter.starter.test_api",
        "documentation": {}
    },
    {
        "label": "test_post_greater_than_fifty",
        "kind": 2,
        "importPath": "starter.starter.test_api",
        "description": "starter.starter.test_api",
        "peekOfCode": "def test_post_greater_than_fifty(greater_than_fifty_sample):\n    \"\"\"\n    test_post_greater_than_fifty tests the route /predict for the greater than 50K sample\n    Args:\n        greater_than_fifty_sample (json):   The sample to be tested against the model for the greater than 50K sample\n    \"\"\"\n    r = client.post(\"/predict/\", json=greater_than_fifty_sample)\n    assert r.status_code == 200\n    assert r.json() == \">50K\"\ndef test_post_less_than_fifty(less_than_fifty_sample):",
        "detail": "starter.starter.test_api",
        "documentation": {}
    },
    {
        "label": "test_post_less_than_fifty",
        "kind": 2,
        "importPath": "starter.starter.test_api",
        "description": "starter.starter.test_api",
        "peekOfCode": "def test_post_less_than_fifty(less_than_fifty_sample):\n    \"\"\"\n    test_post_less_than_fifty tests the route /predict for the less than 50K sample\n    Args:\n        less_than_fifty_sample (json): The sample to be tested against the model for the less than 50K sample\n    \"\"\"\n    response = client.post(\"/predict/\", json=less_than_fifty_sample)\n    assert response.status_code == 200\n    assert response.json() == \"<=50K\"",
        "detail": "starter.starter.test_api",
        "documentation": {}
    },
    {
        "label": "client",
        "kind": 5,
        "importPath": "starter.starter.test_api",
        "description": "starter.starter.test_api",
        "peekOfCode": "client = TestClient(app)\n@pytest.fixture(scope='session')\ndef greater_than_fifty_sample():\n    sample = {\n        \"age\": 52,\n        \"workclass\": \"Self-emp-inc\",\n        \"fnlgt\": 287927,\n        \"education\": \"HS-grad\",\n        \"education_num\": 9,\n        \"marital_status\": \"Married-civ-spouse\",",
        "detail": "starter.starter.test_api",
        "documentation": {}
    },
    {
        "label": "data",
        "kind": 2,
        "importPath": "starter.starter.test_model",
        "description": "starter.starter.test_model",
        "peekOfCode": "def data():\n    \"\"\"\n    data fixture\n    Returns:\n        np.array, np.array: features and label\n    \"\"\"\n    X_train = np.array([[1, 2, 3.0, 4, 5, 6],\n                  [7, 8, 9.0, 10, 11, 12],\n                  [14, 15, 1.0, 16, 17, 18],\n                  [1, 2, 5.0, 4, 5, 6],",
        "detail": "starter.starter.test_model",
        "documentation": {}
    },
    {
        "label": "prediction",
        "kind": 2,
        "importPath": "starter.starter.test_model",
        "description": "starter.starter.test_model",
        "peekOfCode": "def prediction():\n    \"\"\"\n    prediction fixture\n    Returns:\n        np.array: prediction \n    \"\"\"\n    return np.array([0, 1, 1, 1, 0])\ndef test_train_model(data):\n    \"\"\"\n    test_train_model tests the type of train_model function",
        "detail": "starter.starter.test_model",
        "documentation": {}
    },
    {
        "label": "test_train_model",
        "kind": 2,
        "importPath": "starter.starter.test_model",
        "description": "starter.starter.test_model",
        "peekOfCode": "def test_train_model(data):\n    \"\"\"\n    test_train_model tests the type of train_model function\n    Args:\n        data (np.array, np.array): features and label arrays\n    \"\"\"\n    X_train, y_train = data\n    lr = RandomForestClassifier()\n    model = train_model(X_train, y_train)\n    assert type(lr) == type(model)",
        "detail": "starter.starter.test_model",
        "documentation": {}
    },
    {
        "label": "test_inference",
        "kind": 2,
        "importPath": "starter.starter.test_model",
        "description": "starter.starter.test_model",
        "peekOfCode": "def test_inference(data):\n    \"\"\"\n    test_inference tests the type of inference function as well as the length of the prediction array\n    Args:\n        data (np.array, np.array): features and label arrays\n    \"\"\"\n    X_train, y_train = data\n    lr = RandomForestClassifier()\n    model = lr.fit(X_train, y_train)\n    prediction = inference(model, X_train)",
        "detail": "starter.starter.test_model",
        "documentation": {}
    },
    {
        "label": "test_compute_model_metrics",
        "kind": 2,
        "importPath": "starter.starter.test_model",
        "description": "starter.starter.test_model",
        "peekOfCode": "def test_compute_model_metrics(data, prediction):\n    \"\"\"\n    test_compute_model_metrics tests the type of precision, recall, and f1-score\n    Args:\n        data (np.array, np.ndarray): features and label arrays\n        prediction (np.array): prediction array\n    \"\"\"\n    _, y = data\n    precision, recall, fbeta = compute_model_metrics(y, prediction)\n    assert isinstance(precision, float), f'precision of type float expected, but got type: {type(precision)}'",
        "detail": "starter.starter.test_model",
        "documentation": {}
    },
    {
        "label": "data_dir",
        "kind": 5,
        "importPath": "starter.starter.train_model",
        "description": "starter.starter.train_model",
        "peekOfCode": "data_dir = \"../data/\"   # the directory where the data is stored.\ndata_path = os.path.join(data_dir + \"census_clean.csv\") # path to the clean data\ndata = load_data(data_path)\n# Optional enhancement, use K-fold cross validation instead of a train-test split.\ntrain, test = train_test_split(data, test_size=0.20)    # 20% of the data will be used for testing\ncat_features = [\n    \"workclass\",\n    \"education\",\n    \"marital-status\",\n    \"occupation\",",
        "detail": "starter.starter.train_model",
        "documentation": {}
    },
    {
        "label": "data_path",
        "kind": 5,
        "importPath": "starter.starter.train_model",
        "description": "starter.starter.train_model",
        "peekOfCode": "data_path = os.path.join(data_dir + \"census_clean.csv\") # path to the clean data\ndata = load_data(data_path)\n# Optional enhancement, use K-fold cross validation instead of a train-test split.\ntrain, test = train_test_split(data, test_size=0.20)    # 20% of the data will be used for testing\ncat_features = [\n    \"workclass\",\n    \"education\",\n    \"marital-status\",\n    \"occupation\",\n    \"relationship\",",
        "detail": "starter.starter.train_model",
        "documentation": {}
    },
    {
        "label": "data",
        "kind": 5,
        "importPath": "starter.starter.train_model",
        "description": "starter.starter.train_model",
        "peekOfCode": "data = load_data(data_path)\n# Optional enhancement, use K-fold cross validation instead of a train-test split.\ntrain, test = train_test_split(data, test_size=0.20)    # 20% of the data will be used for testing\ncat_features = [\n    \"workclass\",\n    \"education\",\n    \"marital-status\",\n    \"occupation\",\n    \"relationship\",\n    \"race\",",
        "detail": "starter.starter.train_model",
        "documentation": {}
    },
    {
        "label": "cat_features",
        "kind": 5,
        "importPath": "starter.starter.train_model",
        "description": "starter.starter.train_model",
        "peekOfCode": "cat_features = [\n    \"workclass\",\n    \"education\",\n    \"marital-status\",\n    \"occupation\",\n    \"relationship\",\n    \"race\",\n    \"sex\",\n    \"native-country\",\n]   ",
        "detail": "starter.starter.train_model",
        "documentation": {}
    },
    {
        "label": "model_dir",
        "kind": 5,
        "importPath": "starter.starter.train_model",
        "description": "starter.starter.train_model",
        "peekOfCode": "model_dir = \"../model/\"  # the directory where the model will be stored.\nsave_model(encoder, os.path.join(model_dir, \"encoder.pkl\")) # save the label encoder\nsave_model(lb, os.path.join(model_dir, \"lb.pkl\")) # save the encoder\nmodel_path = os.path.join(model_dir, \"rf_model.pkl\") # path to the model\nslice_output = os.path.join(model_dir,'/slice_output.txt') # path to the slice output\n# Process the test data with the process_data function.\nX_test, y_test, test_encoder, test_lb = process_data(\n    test, categorical_features=cat_features, label=\"salary\", training=False, encoder=encoder, lb=lb)    # load the encoder and label encoder\n# Train and save a model.\nclassifier = train_model(X_train, y_train)  # train the model",
        "detail": "starter.starter.train_model",
        "documentation": {}
    },
    {
        "label": "model_path",
        "kind": 5,
        "importPath": "starter.starter.train_model",
        "description": "starter.starter.train_model",
        "peekOfCode": "model_path = os.path.join(model_dir, \"rf_model.pkl\") # path to the model\nslice_output = os.path.join(model_dir,'/slice_output.txt') # path to the slice output\n# Process the test data with the process_data function.\nX_test, y_test, test_encoder, test_lb = process_data(\n    test, categorical_features=cat_features, label=\"salary\", training=False, encoder=encoder, lb=lb)    # load the encoder and label encoder\n# Train and save a model.\nclassifier = train_model(X_train, y_train)  # train the model\nsave_model(classifier, model_path)\ny_train_predict = inference(classifier, X_train)    # make predictions on the training data\ntrain_precision, train_recall, train_fbeta = compute_model_metrics(y_train, y_train_predict)    # compute the metrics for the training data",
        "detail": "starter.starter.train_model",
        "documentation": {}
    },
    {
        "label": "slice_output",
        "kind": 5,
        "importPath": "starter.starter.train_model",
        "description": "starter.starter.train_model",
        "peekOfCode": "slice_output = os.path.join(model_dir,'/slice_output.txt') # path to the slice output\n# Process the test data with the process_data function.\nX_test, y_test, test_encoder, test_lb = process_data(\n    test, categorical_features=cat_features, label=\"salary\", training=False, encoder=encoder, lb=lb)    # load the encoder and label encoder\n# Train and save a model.\nclassifier = train_model(X_train, y_train)  # train the model\nsave_model(classifier, model_path)\ny_train_predict = inference(classifier, X_train)    # make predictions on the training data\ntrain_precision, train_recall, train_fbeta = compute_model_metrics(y_train, y_train_predict)    # compute the metrics for the training data\nprint(f\"train_precision: {train_precision}, train_recall: {train_recall}, train_fbeta: {train_fbeta}\")  # print the metrics for the training data",
        "detail": "starter.starter.train_model",
        "documentation": {}
    },
    {
        "label": "classifier",
        "kind": 5,
        "importPath": "starter.starter.train_model",
        "description": "starter.starter.train_model",
        "peekOfCode": "classifier = train_model(X_train, y_train)  # train the model\nsave_model(classifier, model_path)\ny_train_predict = inference(classifier, X_train)    # make predictions on the training data\ntrain_precision, train_recall, train_fbeta = compute_model_metrics(y_train, y_train_predict)    # compute the metrics for the training data\nprint(f\"train_precision: {train_precision}, train_recall: {train_recall}, train_fbeta: {train_fbeta}\")  # print the metrics for the training data\ny_test_predict = inference(classifier, X_test)  # make predictions on the test data\ntest_precision, test_recall, test_fbeta = compute_model_metrics(y_test, y_test_predict) # compute the metrics for the test data\nprint(f\"test_precision: {test_precision}, test_recall: {test_recall}, test_fbeta: {test_fbeta}\")    # print the metrics for the test data\nslice_metrics = evaluate_model_on_column_slices(test, 'education', y_test, y_test_predict)\nmetric_df = pd.DataFrame(slice_metrics, columns=['education_slice', 'precision', 'recall', 'f1'])",
        "detail": "starter.starter.train_model",
        "documentation": {}
    },
    {
        "label": "y_train_predict",
        "kind": 5,
        "importPath": "starter.starter.train_model",
        "description": "starter.starter.train_model",
        "peekOfCode": "y_train_predict = inference(classifier, X_train)    # make predictions on the training data\ntrain_precision, train_recall, train_fbeta = compute_model_metrics(y_train, y_train_predict)    # compute the metrics for the training data\nprint(f\"train_precision: {train_precision}, train_recall: {train_recall}, train_fbeta: {train_fbeta}\")  # print the metrics for the training data\ny_test_predict = inference(classifier, X_test)  # make predictions on the test data\ntest_precision, test_recall, test_fbeta = compute_model_metrics(y_test, y_test_predict) # compute the metrics for the test data\nprint(f\"test_precision: {test_precision}, test_recall: {test_recall}, test_fbeta: {test_fbeta}\")    # print the metrics for the test data\nslice_metrics = evaluate_model_on_column_slices(test, 'education', y_test, y_test_predict)\nmetric_df = pd.DataFrame(slice_metrics, columns=['education_slice', 'precision', 'recall', 'f1'])\nmetric_df.to_csv('../model/slice_output.txt', index=False)",
        "detail": "starter.starter.train_model",
        "documentation": {}
    },
    {
        "label": "y_test_predict",
        "kind": 5,
        "importPath": "starter.starter.train_model",
        "description": "starter.starter.train_model",
        "peekOfCode": "y_test_predict = inference(classifier, X_test)  # make predictions on the test data\ntest_precision, test_recall, test_fbeta = compute_model_metrics(y_test, y_test_predict) # compute the metrics for the test data\nprint(f\"test_precision: {test_precision}, test_recall: {test_recall}, test_fbeta: {test_fbeta}\")    # print the metrics for the test data\nslice_metrics = evaluate_model_on_column_slices(test, 'education', y_test, y_test_predict)\nmetric_df = pd.DataFrame(slice_metrics, columns=['education_slice', 'precision', 'recall', 'f1'])\nmetric_df.to_csv('../model/slice_output.txt', index=False)",
        "detail": "starter.starter.train_model",
        "documentation": {}
    },
    {
        "label": "slice_metrics",
        "kind": 5,
        "importPath": "starter.starter.train_model",
        "description": "starter.starter.train_model",
        "peekOfCode": "slice_metrics = evaluate_model_on_column_slices(test, 'education', y_test, y_test_predict)\nmetric_df = pd.DataFrame(slice_metrics, columns=['education_slice', 'precision', 'recall', 'f1'])\nmetric_df.to_csv('../model/slice_output.txt', index=False)",
        "detail": "starter.starter.train_model",
        "documentation": {}
    },
    {
        "label": "metric_df",
        "kind": 5,
        "importPath": "starter.starter.train_model",
        "description": "starter.starter.train_model",
        "peekOfCode": "metric_df = pd.DataFrame(slice_metrics, columns=['education_slice', 'precision', 'recall', 'f1'])\nmetric_df.to_csv('../model/slice_output.txt', index=False)",
        "detail": "starter.starter.train_model",
        "documentation": {}
    },
    {
        "label": "Data",
        "kind": 6,
        "importPath": "starter.main",
        "description": "starter.main",
        "peekOfCode": "class Data(BaseModel):\n    age: int\n    workclass: str\n    fnlgt: int\n    education: str\n    education_num: int\n    marital_status: str\n    occupation: str\n    relationship: str\n    race: str",
        "detail": "starter.main",
        "documentation": {}
    },
    {
        "label": "say_hello",
        "kind": 2,
        "importPath": "starter.main",
        "description": "starter.main",
        "peekOfCode": "def say_hello():\n    return \"Greetings!!!\"\n@app.post(\"/predict/\")\ndef create_item(data: Data = Body(None,\n                                        example={\n                                            \"age\": 39,\n                                            \"workclass\": \"State-gov\",\n                                            \"fnlgt\": 77516,\n                                            \"education\": \"Bachelors\",\n                                            \"education_num\": 13,",
        "detail": "starter.main",
        "documentation": {}
    },
    {
        "label": "create_item",
        "kind": 2,
        "importPath": "starter.main",
        "description": "starter.main",
        "peekOfCode": "def create_item(data: Data = Body(None,\n                                        example={\n                                            \"age\": 39,\n                                            \"workclass\": \"State-gov\",\n                                            \"fnlgt\": 77516,\n                                            \"education\": \"Bachelors\",\n                                            \"education_num\": 13,\n                                            \"marital_status\": \"Never-married\",\n                                            \"occupation\": \"Adm-clerical\",\n                                            \"relationship\": \"Not-in-family\",",
        "detail": "starter.main",
        "documentation": {}
    },
    {
        "label": "model_path",
        "kind": 5,
        "importPath": "starter.main",
        "description": "starter.main",
        "peekOfCode": "model_path = os.path.join(\n    os.path.dirname(\n        os.path.abspath(__file__)),\n    'model/rf_model.pkl')\nencoder_path = os.path.join(\n    os.path.dirname(\n        os.path.abspath(__file__)),\n    'model/encoder.pkl')\nlb_path = os.path.join(\n    os.path.dirname(",
        "detail": "starter.main",
        "documentation": {}
    },
    {
        "label": "encoder_path",
        "kind": 5,
        "importPath": "starter.main",
        "description": "starter.main",
        "peekOfCode": "encoder_path = os.path.join(\n    os.path.dirname(\n        os.path.abspath(__file__)),\n    'model/encoder.pkl')\nlb_path = os.path.join(\n    os.path.dirname(\n        os.path.abspath(__file__)),\n    'model/lb.pkl')\nmodel = load_model(model_path)\nencoder = load_model(encoder_path)",
        "detail": "starter.main",
        "documentation": {}
    },
    {
        "label": "lb_path",
        "kind": 5,
        "importPath": "starter.main",
        "description": "starter.main",
        "peekOfCode": "lb_path = os.path.join(\n    os.path.dirname(\n        os.path.abspath(__file__)),\n    'model/lb.pkl')\nmodel = load_model(model_path)\nencoder = load_model(encoder_path)\nlb = load_model(lb_path)\ncat_features = [\n    \"workclass\",\n    \"education\",",
        "detail": "starter.main",
        "documentation": {}
    },
    {
        "label": "model",
        "kind": 5,
        "importPath": "starter.main",
        "description": "starter.main",
        "peekOfCode": "model = load_model(model_path)\nencoder = load_model(encoder_path)\nlb = load_model(lb_path)\ncat_features = [\n    \"workclass\",\n    \"education\",\n    \"marital-status\",\n    \"occupation\",\n    \"relationship\",\n    \"race\",",
        "detail": "starter.main",
        "documentation": {}
    },
    {
        "label": "encoder",
        "kind": 5,
        "importPath": "starter.main",
        "description": "starter.main",
        "peekOfCode": "encoder = load_model(encoder_path)\nlb = load_model(lb_path)\ncat_features = [\n    \"workclass\",\n    \"education\",\n    \"marital-status\",\n    \"occupation\",\n    \"relationship\",\n    \"race\",\n    \"sex\",",
        "detail": "starter.main",
        "documentation": {}
    },
    {
        "label": "lb",
        "kind": 5,
        "importPath": "starter.main",
        "description": "starter.main",
        "peekOfCode": "lb = load_model(lb_path)\ncat_features = [\n    \"workclass\",\n    \"education\",\n    \"marital-status\",\n    \"occupation\",\n    \"relationship\",\n    \"race\",\n    \"sex\",\n    \"native-country\",",
        "detail": "starter.main",
        "documentation": {}
    },
    {
        "label": "cat_features",
        "kind": 5,
        "importPath": "starter.main",
        "description": "starter.main",
        "peekOfCode": "cat_features = [\n    \"workclass\",\n    \"education\",\n    \"marital-status\",\n    \"occupation\",\n    \"relationship\",\n    \"race\",\n    \"sex\",\n    \"native-country\",\n]",
        "detail": "starter.main",
        "documentation": {}
    },
    {
        "label": "app",
        "kind": 5,
        "importPath": "starter.main",
        "description": "starter.main",
        "peekOfCode": "app = FastAPI()\nclass Data(BaseModel):\n    age: int\n    workclass: str\n    fnlgt: int\n    education: str\n    education_num: int\n    marital_status: str\n    occupation: str\n    relationship: str",
        "detail": "starter.main",
        "documentation": {}
    },
    {
        "label": "run_sanity_check",
        "kind": 2,
        "importPath": "starter.sanitycheck",
        "description": "starter.sanitycheck",
        "peekOfCode": "def run_sanity_check(test_dir):\n    #assert path.isdir(test_dir), FAIL_COLOR+f\"No direcotry named {test_dir} found in {os.getcwd()}\"\n    print('This script will perform a sanity test to ensure your code meets the criteria in the rubric.\\n')\n    print('Please enter the path to the file that contains your test cases for the GET() and POST() methods')\n    print('The path should be something like abc/def/test_xyz.py')\n    filepath = input('> ')\n    assert path.exists(filepath), f\"File {filepath} does not exist.\"\n    sys.path.append(path.dirname(filepath))\n    module_name = path.splitext(path.basename(filepath))[0]\n    module = importlib.import_module(module_name)",
        "detail": "starter.sanitycheck",
        "documentation": {}
    },
    {
        "label": "FAIL_COLOR",
        "kind": 5,
        "importPath": "starter.sanitycheck",
        "description": "starter.sanitycheck",
        "peekOfCode": "FAIL_COLOR = '\\033[91m'\nOK_COLOR = '\\033[92m'\nWARN_COLOR = '\\033[93m'\ndef run_sanity_check(test_dir):\n    #assert path.isdir(test_dir), FAIL_COLOR+f\"No direcotry named {test_dir} found in {os.getcwd()}\"\n    print('This script will perform a sanity test to ensure your code meets the criteria in the rubric.\\n')\n    print('Please enter the path to the file that contains your test cases for the GET() and POST() methods')\n    print('The path should be something like abc/def/test_xyz.py')\n    filepath = input('> ')\n    assert path.exists(filepath), f\"File {filepath} does not exist.\"",
        "detail": "starter.sanitycheck",
        "documentation": {}
    },
    {
        "label": "OK_COLOR",
        "kind": 5,
        "importPath": "starter.sanitycheck",
        "description": "starter.sanitycheck",
        "peekOfCode": "OK_COLOR = '\\033[92m'\nWARN_COLOR = '\\033[93m'\ndef run_sanity_check(test_dir):\n    #assert path.isdir(test_dir), FAIL_COLOR+f\"No direcotry named {test_dir} found in {os.getcwd()}\"\n    print('This script will perform a sanity test to ensure your code meets the criteria in the rubric.\\n')\n    print('Please enter the path to the file that contains your test cases for the GET() and POST() methods')\n    print('The path should be something like abc/def/test_xyz.py')\n    filepath = input('> ')\n    assert path.exists(filepath), f\"File {filepath} does not exist.\"\n    sys.path.append(path.dirname(filepath))",
        "detail": "starter.sanitycheck",
        "documentation": {}
    },
    {
        "label": "WARN_COLOR",
        "kind": 5,
        "importPath": "starter.sanitycheck",
        "description": "starter.sanitycheck",
        "peekOfCode": "WARN_COLOR = '\\033[93m'\ndef run_sanity_check(test_dir):\n    #assert path.isdir(test_dir), FAIL_COLOR+f\"No direcotry named {test_dir} found in {os.getcwd()}\"\n    print('This script will perform a sanity test to ensure your code meets the criteria in the rubric.\\n')\n    print('Please enter the path to the file that contains your test cases for the GET() and POST() methods')\n    print('The path should be something like abc/def/test_xyz.py')\n    filepath = input('> ')\n    assert path.exists(filepath), f\"File {filepath} does not exist.\"\n    sys.path.append(path.dirname(filepath))\n    module_name = path.splitext(path.basename(filepath))[0]",
        "detail": "starter.sanitycheck",
        "documentation": {}
    },
    {
        "label": "PREDICT_URI",
        "kind": 5,
        "importPath": "api",
        "description": "api",
        "peekOfCode": "PREDICT_URI = \"https://udacity-mlops-nanodegree-app.herokuapp.com/predict\"\nsample = {'age': 42, 'workclass': 'Private', 'fnlgt': 159449, 'education': 'Bachelors', 'education-num': 13, 'marital-status': 'Married-civ-spouse', 'occupation': 'Exec-managerial', 'relationship': 'Husband', 'race': 'White', 'sex': 'Male', 'capital-gain': 5178, 'capital-loss': 0, 'hours-per-week': 40, 'native-country': 'United-States'}\nresponse = requests.post(PREDICT_URI, json = sample)\ndictionary = {\n    'Request body': sample,\n    'Status code': response.status_code,\n    'Response': response.json()\n}\nprint(json.dumps(dictionary, indent=4))",
        "detail": "api",
        "documentation": {}
    },
    {
        "label": "sample",
        "kind": 5,
        "importPath": "api",
        "description": "api",
        "peekOfCode": "sample = {'age': 42, 'workclass': 'Private', 'fnlgt': 159449, 'education': 'Bachelors', 'education-num': 13, 'marital-status': 'Married-civ-spouse', 'occupation': 'Exec-managerial', 'relationship': 'Husband', 'race': 'White', 'sex': 'Male', 'capital-gain': 5178, 'capital-loss': 0, 'hours-per-week': 40, 'native-country': 'United-States'}\nresponse = requests.post(PREDICT_URI, json = sample)\ndictionary = {\n    'Request body': sample,\n    'Status code': response.status_code,\n    'Response': response.json()\n}\nprint(json.dumps(dictionary, indent=4))",
        "detail": "api",
        "documentation": {}
    },
    {
        "label": "response",
        "kind": 5,
        "importPath": "api",
        "description": "api",
        "peekOfCode": "response = requests.post(PREDICT_URI, json = sample)\ndictionary = {\n    'Request body': sample,\n    'Status code': response.status_code,\n    'Response': response.json()\n}\nprint(json.dumps(dictionary, indent=4))",
        "detail": "api",
        "documentation": {}
    },
    {
        "label": "dictionary",
        "kind": 5,
        "importPath": "api",
        "description": "api",
        "peekOfCode": "dictionary = {\n    'Request body': sample,\n    'Status code': response.status_code,\n    'Response': response.json()\n}\nprint(json.dumps(dictionary, indent=4))",
        "detail": "api",
        "documentation": {}
    }
]